# API Keys
OPENAI_API_KEY=your_openai_api_key_here
GROQ_API_KEY=your_groq_api_key_here
LLAMA_CLOUD_API_KEY=your_llama_cloud_api_key_here
LLAMA_CLOUD_PROJECT_ID=your_project_id_here
LLAMA_CLOUD_ORG_ID=your_org_id_here

# LLM Configuration
# Provider: "openai" or "groq"
LLM_PROVIDER=openai

# Model selection (depends on provider)
# OpenAI models: gpt-5-nano, gpt-4o, gpt-4o-mini
# Groq models: moonshotai/kimi-k2-instruct-0905, llama-3.3-70b-versatile, mixtral-8x7b-32768
LLM_MODEL=gpt-5-nano

# Legacy OpenAI Configuration (deprecated - use LLM_PROVIDER and LLM_MODEL instead)
# Model to use for all OpenAI API calls (classification, schema inference, extraction, validation)
OPENAI_MODEL=gpt-5-nano

# Temperature settings for different operations (0.0 = deterministic, 1.0 = creative)
OPENAI_TEMPERATURE_CLASSIFICATION=0.3
OPENAI_TEMPERATURE_SCHEMA=0.3
OPENAI_TEMPERATURE_EXTRACTION=0.1
OPENAI_TEMPERATURE_VALIDATION=0.1

# Validation Configuration
# Enable/disable automatic validation of extracted data
ENABLE_VALIDATION=true

# Minimum confidence score (0.0-1.0) required to auto-apply corrections
VALIDATION_MIN_CONFIDENCE=0.8

# Enable specific validation checks
VALIDATION_CHECK_CALCULATIONS=true
VALIDATION_DETECT_OCR_ERRORS=true
VALIDATION_CHECK_BUSINESS_LOGIC=true
